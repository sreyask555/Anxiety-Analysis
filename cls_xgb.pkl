import pandas as pd
from xgboost import XGBClassifier
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.metrics import classification_report, accuracy_score, f1_score
import joblib

df = pd.read_csv("preprocessed_data/final_scaled_dataset.csv")
X = df.drop(columns=["Severity of Anxiety Attack (1-10)"])

y = df["Severity of Anxiety Attack (1-10)"] - 1 

X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.05, stratify=y, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=(5/95), stratify=y_train_val, random_state=42)

xgb = XGBClassifier(random_state=42, eval_metric="mlogloss", use_label_encoder=False)
param_dist = {
    'n_estimators': [500,700],
    'max_depth': [20,25],
    'learning_rate': [0.01, 0.1, 0.2],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0]
}

random_search = RandomizedSearchCV(xgb, param_distributions=param_dist, n_iter=20, cv=3, scoring='f1_macro', verbose=2, n_jobs=-1, random_state=42)
random_search.fit(X_train, y_train)
best_model = random_search.best_estimator_

def evaluate(name, model, X, y):
    pred = model.predict(X)
    print(f"\n{name}")
    print("Accuracy:", accuracy_score(y, pred))
    print("F1 Score (macro):", f1_score(y, pred, average="macro"))
    print("Classification Report:\n", classification_report(y, pred))

evaluate("Train", best_model, X_train, y_train)
evaluate("Validation", best_model, X_val, y_val)
evaluate("Test", best_model, X_test, y_test)

joblib.dump(best_model, "models/xgb_classifier_model.pkl")
print("XGBoost Classifier saved.")
print("Best Model is:",best_model)
